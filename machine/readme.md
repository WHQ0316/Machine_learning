# 机器学习

---
###### 1.分类
###### 2.回归
###### 3.聚类
###### 4.降维
###### 5.去噪

---
###### SVM
###### 决策树
###### K最邻近（KNN）
###### K-means
###### 线性回归（一元或多元）

---
### 库函数
###### pip install -U scikit-learn
###### pip install numpy
###### pip install jupyter
###### pip install pandas

---
## SKlearn库

---
### 数据预处理： 
###### 数据重复（重复值删除） 
###### 数据偏斜
###### 数据冗余
###### 噪声
###### 异常值（检测、替换）
###### 缺失数据（删除、填充、预测）
###### 数据转换（离散化、标准化、对数转换）
###### 数据压缩（主成分分析、线性判别分析）
###### --------------------------------------
###### 归一化：
###### 最大最小值归一化:
###### preprocessing.MinMaxScaler()
###### 均值方差归一化:
###### preprocessing.StandardScaler()

---
## 分类
###### --------------------------------------
##### 朴素贝叶斯(条件概率)
##### KNN(K最邻近)
###### --------------------------------------
###### KNN
###### 距离度量
###### K值选择
###### 分类决策的规则
###### --------------------------------------
##### 案例：
###### egg1、鸢尾花分类

---
## 决策树
###### --------------------------------------
###### 选择最优特征
###### 确定分割点
###### （剪枝机制--防止过拟合）
###### --------------------------------------
##### 算法：
###### ID3（信息增益）---（熵）
###### CART（分类与回归树）---（基尼指数）

---
## SVM
###### --------------------------------------
###### 核函数（将非线性映射为‘高维’线性特征）
###### 超平面
###### 常用核函数：线性核、高斯核、多项式核、拉普拉斯核、Sigmoid核

---
## 回归分析
###### 
######
######
######
######
######

---
## 聚类分析（无监督学习）
###### 相似性、距离
#### 算法：
##### 1.基于划分：k-Means、k-Medoids、CLARA
##### 2.基于层次：单/全连接、CURE
###### 3.基于密度：DBSCAN、DENCLUE
###### 4.基于网络：STINFG、WaveCluster
###### 5.基于模型：COBWEB、SOM

